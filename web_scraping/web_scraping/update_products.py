# for updateing the products collection, if anything changed

import pandas as pd, numpy as np, json

# products_old.json is from the database products collection
df_old=pd.read_json("products_old.json", lines=True)
df_new=pd.read_json("products.json", lines=True)

# dropping the id generated by mongodb
df_old=df_old.drop('_id',axis=1)

# rename the column that could changed
df_new=df_new.rename(columns={"sold_by":"sold_by_new"})

# checking if the new data's sold_by column has changed (if the item appeared on a site or disappeared)
df_final=pd.merge(df_old, df_new[['sold_by_new','id','name']], on=['id','name'], how="inner")
df_filtered=df_final[(df_final.sold_by != df_final.sold_by_new)]

# if changed keeping the new data
df_filtered=df_filtered.drop(columns={'sold_by'})
df_filtered=df_filtered.rename(columns={'sold_by_new':'sold_by'})
df_filtered.to_json('products_update.json', orient='records', lines=True)

# collecting the new data's url, in order to scrape it's specifications later
df_new=pd.read_json('products.json',lines=True)
df_old = df_old.fillna(value=np.nan)

# keep only what's new (items only in the new dataframe)
df_products_new=pd.merge(df_old[['name']],df_new,on=['name'],how="right", indicator=True).query('_merge=="right_only"')
df_products_new=df_products_new.drop(columns={"_merge"})
df_products_new.to_json('new_items.json', orient='records', lines=True)

# save the links only
df_links=df_products_new['emag_url']
df_links.to_json('emag_revisit_links.json', orient='records')


